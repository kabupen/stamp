
\chapter{Pythonと学ぶ統計}
\section{最小二乗法 (least square)}
python/chi\_square.py
$N$組のデータ$(x_i,y_i)$を測定した($i=1,...,N$)。これらを尤もらしく表すことができる関数$y=f(x)$を求めたい。
想定する状況は、実験者が$x_i$を固定して、$y_i$を測定していく、というもの。
各$y_i$はとある平均値の周りにふらつきを持って測定される。以下では簡単に線形近似の場合を考える。
\begin{equation}
  y = ax + b
\end{equation}
の係数を実験データから求めたい。そこで次のような値を考える。

\begin{equation}
  \Phi(a,b) = \sum_{i=1}^{N} w_i r_i^{2} = \sum_{i=1}^{n} w_i[f(x_i)-y_i]^2
\end{equation}

$r_i$は残差（residual）と呼ばれる値であり、データ点とモデル曲線との差を表している。
$w_i$は各データ点に対する重みであり、分散の逆数に比例した値を持つ。
仮に$w_i$が$1/\sigma_i^2$に全く等しい場合、$\Phi$は$\chi^2$に等しくなるため、最小二乗フィットはカイ自乗フィットとも呼ばれる。


誤差を含むような実験データ値から、もっともらしい関数の形を決定する時に用いられる手法。
$n$個のデータ点$(x_1,y_1), (x_2,y_2), ... (x_n, y_n)$をフィットする際に（関数の形は経験的に決定する）指標として用いる。
